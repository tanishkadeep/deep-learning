{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFBj6FrhiHVq",
        "outputId": "c18170db-c43e-4f92-d86b-f944a5a25127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebbian Weights: [[0.75770207 0.97793932 0.40247765]\n",
            " [0.27626824 0.5458531  0.40109061]\n",
            " [0.63342983 0.19151917 0.82593941]]\n",
            "\n",
            "Perceptron Weights: [0.26665818 0.23433659 0.51397828]\n",
            "\n",
            "Delta Weights: [[0.56554047 0.28672249 0.90275812]\n",
            " [0.13174521 0.02089043 0.88380856]\n",
            " [0.17147318 0.50038481 0.62785448]]\n",
            "\n",
            "Correlation Weights: [[0.82638525 0.05183879 0.07039659]\n",
            " [0.17957817 0.78727131 0.59921633]\n",
            " [0.88137276 0.84608234 0.08336776]]\n",
            "\n",
            "Out Star Weights: [[0.966868   0.32276158 0.86425047]\n",
            " [0.78658872 0.75108191 0.10347332]\n",
            " [0.41994101 0.93459702 0.92271653]]\n",
            "\n",
            "Hebbian Updated Weights: [[0.79770207 1.07793932 0.56247765]\n",
            " [0.37626824 0.7958531  0.80109061]\n",
            " [0.79342983 0.59151917 1.46593941]]\n",
            "\n",
            "Perceptron Updated Weights: [0.27502453 0.25525246 0.54744368]\n",
            "\n",
            "Delta Updated Weights: [[0.56596695 0.2877887  0.90446406]\n",
            " [0.13686839 0.03369837 0.90430127]\n",
            " [0.17573777 0.51104627 0.64491283]]\n",
            "\n",
            "Correlation Updated Weights: [[0.86638525 0.15183879 0.23039659]\n",
            " [0.27957817 1.03727131 0.99921633]\n",
            " [1.04137276 1.24608234 0.72336776]]\n",
            "\n",
            "Out Star Updated Weights: [[0.970868   0.33276158 0.88025047]\n",
            " [0.79658872 0.77608191 0.14347332]\n",
            " [0.43594101 0.97459702 0.98671653]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hebbian Learning Rule\n",
        "def hebbian_learning_rule(input_pattern, weight_matrix):\n",
        "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
        "\n",
        "# Perceptron Learning Rule\n",
        "def perceptron_learning_rule(input_pattern, target, weight_vector, learning_rate):\n",
        "    prediction = np.dot(weight_vector, input_pattern)\n",
        "    error = target - prediction\n",
        "    return weight_vector + learning_rate * error * input_pattern\n",
        "\n",
        "# Delta Learning Rule\n",
        "def delta_learning_rule(input_pattern, target, weight_matrix, learning_rate):\n",
        "    prediction = np.dot(weight_matrix, input_pattern)\n",
        "    error = target - prediction\n",
        "    return weight_matrix + learning_rate * np.outer(error, input_pattern)\n",
        "\n",
        "# Correlation Learning Rule\n",
        "def correlation_learning_rule(input_pattern, weight_matrix):\n",
        "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
        "\n",
        "# Out Star Learning Rule\n",
        "def out_star_learning_rule(input_pattern, weight_matrix, learning_rate):\n",
        "    return weight_matrix + learning_rate * np.outer(input_pattern, input_pattern)\n",
        "\n",
        "# Initialize weights with random values\n",
        "input_size = 3\n",
        "hebbian_weights = np.random.rand(input_size, input_size)\n",
        "perceptron_weights = np.random.rand(input_size)\n",
        "delta_weights = np.random.rand(input_size, input_size)\n",
        "correlation_weights = np.random.rand(input_size, input_size)\n",
        "out_star_weights = np.random.rand(input_size, input_size)\n",
        "\n",
        "print(\"Hebbian Weights:\", hebbian_weights)\n",
        "print(\"\\nPerceptron Weights:\", perceptron_weights)\n",
        "print(\"\\nDelta Weights:\", delta_weights)\n",
        "print(\"\\nCorrelation Weights:\", correlation_weights)\n",
        "print(\"\\nOut Star Weights:\", out_star_weights)\n",
        "\n",
        "# Sample input and target data\n",
        "input_pattern = np.array([0.2, 0.5, 0.8])\n",
        "target = 1\n",
        "\n",
        "# Apply learning rules\n",
        "hebbian_weights_updated = hebbian_learning_rule(input_pattern, hebbian_weights)\n",
        "perceptron_weights_updated = perceptron_learning_rule(input_pattern, target, perceptron_weights, learning_rate=0.1)\n",
        "delta_weights_updated = delta_learning_rule(input_pattern, target, delta_weights, learning_rate=0.1)\n",
        "correlation_weights_updated = correlation_learning_rule(input_pattern, correlation_weights)\n",
        "out_star_weights_updated = out_star_learning_rule(input_pattern, out_star_weights, learning_rate=0.1)\n",
        "\n",
        "# Display updated weights\n",
        "print(\"\\nHebbian Updated Weights:\", hebbian_weights_updated)\n",
        "print(\"\\nPerceptron Updated Weights:\", perceptron_weights_updated)\n",
        "print(\"\\nDelta Updated Weights:\", delta_weights_updated)\n",
        "print(\"\\nCorrelation Updated Weights:\", correlation_weights_updated)\n",
        "print(\"\\nOut Star Updated Weights:\", out_star_weights_updated)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6sObtcfiIHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}