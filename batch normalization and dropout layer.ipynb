{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Study the effect of batch normalization and dropout in neural network classifier\n",
        "\n",
        "## Batch Normalization:\n",
        "\n",
        "Batch normalization is a technique used to improve the training of artificial neural networks by normalizing the input of each layer. It helps in stabilizing and accelerating the training process by reducing internal covariate shift. In simpler terms, it normalizes the input of each layer, which helps in preventing vanishing gradients and allows for faster convergence during training.\n",
        "\n",
        "## Dropout:\n",
        "\n",
        "Dropout is a regularization technique used during training to prevent overfitting. It works by randomly dropping a certain percentage of neurons (along with their connections) from the neural network during each training iteration. This helps in preventing the network from relying too much on any specific set of neurons, thus improving generalization and reducing overfitting."
      ],
      "metadata": {
        "id": "ubHJWOekAWj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "XaLNHkkmAtPX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uMLFFMLAv8m",
        "outputId": "52abd6c8-85af-4ca5-a32f-0c6bb87ee6c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),  # Adding Batch Normalization layer\n",
        "        Dropout(0.2),          # Adding Dropout layer with dropout rate of 0.2\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "7gG7H4sNA-Xu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jficybcfAGwt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX-u-U5hAvBW",
        "outputId": "fb979543-e745-45ae-9c1d-0aa6e7bb8d76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 17s 5ms/step - loss: 0.3437 - accuracy: 0.8972 - val_loss: 0.1352 - val_accuracy: 0.9602\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1931 - accuracy: 0.9423 - val_loss: 0.1178 - val_accuracy: 0.9640\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1613 - accuracy: 0.9512 - val_loss: 0.0954 - val_accuracy: 0.9705\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1370 - accuracy: 0.9585 - val_loss: 0.0875 - val_accuracy: 0.9733\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1258 - accuracy: 0.9621 - val_loss: 0.0811 - val_accuracy: 0.9733\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1150 - accuracy: 0.9642 - val_loss: 0.0779 - val_accuracy: 0.9761\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1043 - accuracy: 0.9685 - val_loss: 0.0693 - val_accuracy: 0.9788\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0968 - accuracy: 0.9698 - val_loss: 0.0732 - val_accuracy: 0.9776\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0934 - accuracy: 0.9706 - val_loss: 0.0677 - val_accuracy: 0.9788\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0862 - accuracy: 0.9726 - val_loss: 0.0719 - val_accuracy: 0.9773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
        "print(\"Train Loss:\", train_loss)\n",
        "print(\"Train accuracy:\", train_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIzJ4YhuBaQ5",
        "outputId": "e84018a1-1cc3-4ce5-9614-690b22f9433d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0308 - accuracy: 0.9904\n",
            "Train Loss: 0.0308497603982687\n",
            "Train accuracy: 0.9903500080108643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKMwtljgBVdC",
        "outputId": "ccce28bc-3639-43c7-c935-d87b4fa5d3b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9773\n",
            "Test Loss: 0.07185625284910202\n",
            "Test accuracy: 0.9772999882698059\n"
          ]
        }
      ]
    }
  ]
}